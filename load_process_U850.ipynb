{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "empty-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from numpy import nan\n",
    "from constants import *\n",
    "import sys\n",
    "import warnings\n",
    "import math\n",
    "import os\n",
    "import cftime\n",
    "from glob import glob\n",
    "from timeit import default_timer as timer # try to measure time\n",
    "from CASutils import readdata_utils as read\n",
    "from CASutils import calendar_utils as cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e2c17e2-ae0b-4537-998d-406d01e800c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define functions\n",
    "def read_cmip6(filepath,datestart,dateend):\n",
    "    #open netcdf dataset\n",
    "    dat = xr.open_mfdataset(filepath, coords=\"minimal\", join=\"override\", decode_times = True, use_cftime=True)  \n",
    "    #convert calendar to standard, setting missing values as NaNs\n",
    "    dat = dat.convert_calendar(\"standard\", use_cftime=True, align_on=\"date\",missing=np.nan)\n",
    "    #interpolate the dataset using cftim_range\n",
    "    dateidx = xr.cftime_range(datestart,dateend,freq='D',calendar=\"standard\") \n",
    "    dat = dat.interp(time=dateidx,method=\"nearest\") \n",
    "    #take slice\n",
    "    dat = dat.sel(time=slice(datestart, dateend))\n",
    "    dat = xr.decode_cf(dat, use_cftime = True) \n",
    "    return dat\n",
    "\n",
    "#def read_field(filepath, datestart, dateend,latmin,latmax,plev):\n",
    "#    \"\"\"Read in a time slice from datestart to dateend and calculate the zonal mean.\n",
    "#    Try using datetime64 and if that doesn't work decode times manually.\n",
    "#    Args:\n",
    "#        filepath (string) = path to files e.g., \"/path/to/files/*.nc\"\n",
    "#        datestart (string) = start date for time slice\n",
    "#        dateend (string) = end date for time slice\n",
    "#    \"\"\"\n",
    "#\n",
    "#    try:\n",
    "#        dat = xr.open_mfdataset(filepath, coords=\"minimal\", join=\"override\",\n",
    "#                 decode_times=True, use_cftime=True).\\\n",
    "#                 sel(time=slice(datestart, dateend),lat=slice(latmin,latmax),plev=plev)\n",
    "#\n",
    "#    except:\n",
    "#                \n",
    "#        print(\"Something's wierd about the time axis, decoding manually\")\n",
    "#        dat = xr.open_mfdataset(filepath, coords=\"minimal\", join=\"override\",\n",
    "#                   decode_times=False)\n",
    "#\n",
    "#        dat=xr.decode_cf(dat, use_cftime=True)\n",
    "#        dat=dat.sel(time=slice(datestart, dateend),lat=slice(latmin,latmax),plev=plev)\n",
    "#        datetimeindex=dat.indexes['time'].to_datetimeindex()\n",
    "#        dat['time'] = datetimeindex\n",
    "#\n",
    "#    return dat\n",
    "\n",
    "#def read_field(filepath, datestart, dateend,latmin,latmax,plev):\n",
    "#    \"\"\"Read in a time slice from datestart to dateend and calculate the zonal mean.\n",
    "#    Try using datetime64 and if that doesn't work decode times manually.\n",
    "#    Args:\n",
    "#        filepath (string) = path to files e.g., \"/path/to/files/*.nc\"\n",
    "#        datestart (string) = start date for time slice\n",
    "#        dateend (string) = end date for time slice\n",
    "#    \"\"\"\n",
    "#\n",
    "#    try:\n",
    "#        dat = xr.open_mfdataset(filepath, coords=\"minimal\", join=\"override\",\n",
    "#                 decode_times=True, use_cftime=True)\n",
    "#\n",
    "#    except:\n",
    "#                \n",
    "#        print(\"Something's wierd about the time axis, decoding manually\")\n",
    "#        dat = xr.open_mfdataset(filepath, coords=\"minimal\", join=\"override\",\n",
    "#                   decode_times=False)\n",
    "#\n",
    "#        dat=xr.decode_cf(dat, use_cftime=True)\n",
    "#        datetimeindex=dat.indexes['time'].to_datetimeindex()\n",
    "#        dat['time'] = datetimeindex\n",
    "#        \n",
    "#    dat=dat.sel(time=slice(datestart, dateend),lat=slice(latmin,latmax),plev=plev)\n",
    "#    return dat\n",
    "\n",
    "def read_field(filepath, datestart, dateend,latmin,latmax,lonmin,lonmax,plev):\n",
    "    \"\"\"Read in a time slice from datestart to dateend and calculate the zonal mean.\n",
    "    Try using datetime64 and if that doesn't work decode times manually.\n",
    "    Args:\n",
    "        filepath (string) = path to files e.g., \"/path/to/files/*.nc\"\n",
    "        datestart (string) = start date for time slice\n",
    "        dateend (string) = end date for time slice\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        dat = xr.open_mfdataset(filepath, coords=\"minimal\", join=\"override\",\n",
    "                 decode_times=True, use_cftime=True).\\\n",
    "                 sel(time=slice(datestart, dateend),lat=slice(latmin,latmax),lon=slice(lonmin,lonmax))\n",
    "        \n",
    "        if len(plev) == 1:\n",
    "            dat = dat.sel(plev=plev,method=\"nearest\", tolerance=1) #avoid issue for models with inaccurate plevs\n",
    "        else:\n",
    "            dat = dat.sel(plev=slice(plev[0]+1,plev[1]-1)) #manual tolerance of 1 because method=\"nearest\" is not implemented for slices\n",
    "\n",
    "    except:\n",
    "        print(\"Something's wierd about the time axis, decoding manually\")\n",
    "        dat = xr.open_mfdataset(filepath, coords=\"minimal\", join=\"override\",\n",
    "                   decode_times=False)\n",
    "            \n",
    "        dat=xr.decode_cf(dat, use_cftime=True)\n",
    "    \n",
    "        dat=dat.sel(time=slice(datestart, dateend),lat=slice(latmin,latmax),lon=slice(lonmin,lonmax))\n",
    "        if len(plev) == 1:\n",
    "            dat = dat.sel(plev=plev,method=\"nearest\", tolerance=1) #avoid issue for models with inaccurate plevs\n",
    "        else:\n",
    "            dat = dat.sel(plev=slice(plev[0]+1,plev[1]-1))  #manual tolerance of 1 because method=\"nearest\" is not implemented for slices\n",
    "\n",
    "        datetimeindex=dat.indexes['time'].to_datetimeindex()\n",
    "        dat['time'] = datetimeindex\n",
    "\n",
    "    return dat\n",
    "\n",
    "\n",
    "def get_lat_lon_res(ds):\n",
    "    '''Function to obtain the average lat and lon gridspacing from a dataset of a non regular model grid. '''\n",
    "    lat = ds.coords['lat']\n",
    "    lon = ds.coords['lon']\n",
    "    difflat = lat - lat.shift(lat=1)\n",
    "    latres = difflat.mean().to_numpy()\n",
    "    difflon = lon - lon.shift(lon=1)\n",
    "    lonres = difflon.mean().to_numpy()\n",
    "    return latres, lonres\n",
    "\n",
    "def def_domain(ncdf,min_lat,max_lat,min_lon,max_lon):\n",
    "    LatIndexer, LonIndexer = 'lat', 'lon'\n",
    "    ncdf = ncdf.loc[{LatIndexer: slice(min_lat, max_lat),\n",
    "                      LonIndexer: slice(min_lon, max_lon)}]\n",
    "    return ncdf\n",
    "\n",
    "def norm_lon(ncdf):\n",
    "    ncdf.coords['lon'] = (ncdf.coords['lon'] + 180) % 360 - 180\n",
    "    return ncdf.sortby(ncdf.lon)\n",
    "\n",
    "def get_ONDJFM_day(ncdf, months=[1,2,3,10,11,12],timedim=\"day\"):\n",
    "    return ncdf.isel({timedim:ncdf[timedim].dt.month.isin(months)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dental-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/lseverino/MT/scripts')\n",
    "importlib.reload(read)\n",
    "importlib.reload(cal)\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vocational-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants\n",
    "#paths\n",
    "histpath=\"/net/atmos/data/cmip6/historical/\"\n",
    "ssp119path=\"/net/atmos/data/cmip6/ssp119/\"\n",
    "ssp126path=\"/net/atmos/data/cmip6/ssp126/\"\n",
    "ssp245path=\"/net/atmos/data/cmip6/ssp245/\"\n",
    "ssp370path=\"/net/atmos/data/cmip6/ssp370/\"\n",
    "ssp585path=\"/net/atmos/data/cmip6/ssp585/\"\n",
    "\n",
    "scenlist = [\"historical\",\"ssp126\",\"ssp245\",\"ssp370\",\"ssp585\"]\n",
    "pathlist = [histpath,ssp126path,ssp245path,ssp370path,ssp585path]\n",
    "pathdic = {\"historical\":histpath,\"ssp126\":ssp126path,\"ssp245\":ssp245path,\"ssp370\":ssp370path,\"ssp585\":ssp585path}\n",
    "tres = \"Amon/\"\n",
    "var=\"ua\"\n",
    "pathout=\"../cmip6/\"+var+'/'\n",
    "\n",
    "cmip6models=pd.read_csv('../cmip6csvinfo/cmip6csvinfo_timeseries_ssp585_luca_daily.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e5326c-f583-4f41-95e8-2cbf450365b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### constants\n",
    "#select variable (cmip6 naming)\n",
    "selvar = 'psl'\n",
    "#dict for abbreviations of the cmip6 variables names\n",
    "cmip6vars = {'sfcWindmax':'SWM','sfcWind':'SW','psl':'SLP','ua':'UA',}\n",
    "##preprocessing and objects constants\n",
    "gst_fact = 1.67\n",
    "qt = 0.98\n",
    "min_lat=0\n",
    "max_lat=90\n",
    "min_lon=0\n",
    "max_lon=357.5\n",
    "\n",
    "##climada constants\n",
    "haz_type = 'WS'\n",
    "haz_id = 1\n",
    "\n",
    "## naming\n",
    "#name base (meteo) variable\n",
    "metvar = [cmip6vars[selvar]]\n",
    "spaceres = [\"br\"] #base resolution regridded\n",
    "timeres = [\"mon\"]\n",
    "domain = [\"NH\"]\n",
    "season = [\"winE\"]\n",
    "processings = [\"qt98\",\"gst1-67\",\"cutarea0\",\"cal1\"]\n",
    "sep = \"_\"\n",
    "lst_bn = metvar+spaceres+timeres+domain+season\n",
    "basenamemet = sep.join(lst_bn)\n",
    "lst_bn_proc = processings+metvar+spaceres+timeres+domain+season\n",
    "basenamemet_proc = sep.join(lst_bn_proc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "political-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directories and member names\n",
    "nmems_hist = dict()\n",
    "#nmems_ssp119 = dict()\n",
    "nmems_ssp126 = dict()\n",
    "nmems_ssp245 = dict()\n",
    "nmems_ssp370 = dict()\n",
    "nmems_ssp585 = dict()\n",
    "models_df = pd.DataFrame(columns=scenlist)\n",
    "for ind,path in enumerate(pathlist):\n",
    "    for subdir in os.scandir(path+tres+var):\n",
    "        models_df.loc[subdir.name,scenlist[ind]] = len(os.listdir(subdir))\n",
    "    \n",
    "models_df.loc[\"total\",:] = models_df.count(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6361a1-a79c-4efe-ace7-37d397258d74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>historical</th>\n",
       "      <th>ssp126</th>\n",
       "      <th>ssp245</th>\n",
       "      <th>ssp370</th>\n",
       "      <th>ssp585</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AWI-CM-1-1-MR</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCC-CSM2-MR</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCC-ESM1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CESM2-WACCM</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CESM2</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GISS-E2-2-H</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICON-ESM-LR</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GISS-E2-2-G</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UKESM1-1-LL</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>66</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>44</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              historical ssp126 ssp245 ssp370 ssp585\n",
       "AWI-CM-1-1-MR          5      1      1      5      1\n",
       "BCC-CSM2-MR            3      1      1      1      1\n",
       "BCC-ESM1               3    NaN    NaN      3    NaN\n",
       "CESM2-WACCM            3      1      5      3      5\n",
       "CESM2                 11      5      6      8      5\n",
       "...                  ...    ...    ...    ...    ...\n",
       "GISS-E2-2-H            5    NaN    NaN    NaN    NaN\n",
       "ICON-ESM-LR            5    NaN    NaN    NaN    NaN\n",
       "GISS-E2-2-G           11      5      5      5      5\n",
       "UKESM1-1-LL            1      1    NaN      1    NaN\n",
       "total                 66     48     48     44     50\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dried-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all models with minimum 3 members for the 5 scenarios\n",
    "mods_3mem_allscen = models_df.where(models_df>=3).dropna(how='any').iloc[:-1,:]\n",
    "mods_1mem_allscen = models_df.where(models_df>=1).dropna(how='any').iloc[:-1,:]\n",
    "mods_1mem_hist_ssp585= models_df[[\"historical\",\"ssp585\"]].where(models_df>=1).dropna(how='any').iloc[:-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3bf4757-e7dd-4d0a-aa1f-02497b14cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>historical</th>\n",
       "      <th>ssp585</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AWI-CM-1-1-MR</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCC-CSM2-MR</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CESM2-WACCM</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HadGEM3-GC31-LL</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFDL-CM4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAMS-CSM1-0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NESM3</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFDL-ESM4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorESM2-LM</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCM-UA-1-0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPI-ESM1-2-HR</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FGOALS-f3-L</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNRM-CM6-1-HR</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INM-CM4-8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INM-CM5-0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIO-ESM-2-0</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HadGEM3-GC31-MM</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NorESM2-MM</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CIESM</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IITM-ESM</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TaiESM1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-1-ECA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAS-ESM2-0</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMCC-CM2-SR5</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIOST-ESM</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EC-Earth3-CC</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CMCC-ESM2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                historical ssp585\n",
       "AWI-CM-1-1-MR            5      1\n",
       "BCC-CSM2-MR              3      1\n",
       "CESM2-WACCM              3      5\n",
       "HadGEM3-GC31-LL          5      4\n",
       "GFDL-CM4                 1      1\n",
       "CAMS-CSM1-0              3      2\n",
       "E3SM-1-0                 5      5\n",
       "NESM3                    5      2\n",
       "GFDL-ESM4                3      1\n",
       "NorESM2-LM               3      1\n",
       "MCM-UA-1-0               2      1\n",
       "MPI-ESM1-2-HR           10      2\n",
       "FGOALS-f3-L              3      1\n",
       "CNRM-CM6-1-HR            1      1\n",
       "INM-CM4-8                1      1\n",
       "INM-CM5-0               10      1\n",
       "FIO-ESM-2-0              3      3\n",
       "E3SM-1-1                 1      1\n",
       "HadGEM3-GC31-MM          4      4\n",
       "NorESM2-MM               3      1\n",
       "CIESM                    3      1\n",
       "IITM-ESM                 1      1\n",
       "TaiESM1                  2      1\n",
       "E3SM-1-1-ECA             1      1\n",
       "CAS-ESM2-0               4      2\n",
       "CMCC-CM2-SR5            11      1\n",
       "KIOST-ESM                1      1\n",
       "EC-Earth3-CC            10      1\n",
       "CMCC-ESM2                1      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mods_1mem_hist_ssp585.drop(index=mods_3mem_allscen.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "focused-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_diff = pd.DataFrame()\n",
    "for scen in scenlist[1:]:\n",
    "    colname =  scen+\" - hist\"\n",
    "    models_diff.loc[:,colname] = abs(models_df.loc[::-1,scen]-models_df.loc[::-1,\"historical\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "allied-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get populate dict with model names and member names\n",
    "# force to get the same members as for sfcWindmax\n",
    "varSWM = 'sfcWindmax'\n",
    "tresSWM = 'day/'\n",
    "dicscen = dict()\n",
    "for ind,scen in enumerate(scenlist):\n",
    "    path = pathlist[ind]\n",
    "    dicscen[scen] = dict()\n",
    "    for subdir in os.scandir(path+tresSWM+varSWM):\n",
    "        #models_rcp85[subdir.name]=[]\n",
    "        dicscen[scen][subdir.name] = [len(os.listdir(subdir))]\n",
    "        dicscen[scen][subdir.name].append(os.listdir(subdir))\n",
    "nmems_hist = dicscen['historical']\n",
    "nmems_ssp585 = dicscen['ssp585']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "designing-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn dicts into pd DataFrames because more convenient\n",
    "nmems_hist_df = pd.DataFrame(nmems_hist, index=[\"hist\",\"memnames\"])\n",
    "nmems_ssp585_df = pd.DataFrame(nmems_ssp585, index=[\"ssp585\",\"memnames\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "celtic-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get common models that are both in historical and rcp85\n",
    "nmems_hist_com = nmems_hist_df.reindex(nmems_ssp585_df.columns,axis=1).dropna(axis=1)\n",
    "nmems_ssp585_com = nmems_ssp585_df.reindex(nmems_hist_df.columns,axis=1).dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "neural-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider ONJDFM: start in D, finishes in M, adjust to have same number of days in both periods\n",
    "ybegp = 1980 ; monbegp = 10 ; yendp = 2010 ; monendp = 3 ; daybegp = 1 ; dayendp = 30# dates for Past period, only takes 30th \n",
    "#ybegf = 2070 ; monbegf = 1 ; yendf = 2099 ; monendf = 12 ; daybegf = 1 ; dayendf = 31# dates for Future period\n",
    "ybegf = 2070 ; monbegf = 10 ; yendf = 2100 ; monendf = 3 ; daybegf = 1 ; dayendf = 30# otherwise dont have the same length\n",
    "\n",
    "# total number of months (used for checking)\n",
    "nmonthsp = (yendp-ybegp-1)*12 + (12-monbegp+1) + monendp\n",
    "nmonthsf = (yendf-ybegf-1)*12 + (12-monbegf+1) + monendf\n",
    "\n",
    "# set up date names\n",
    "dateformat ='%Y-%m-%d'\n",
    "\n",
    "datebegp=str(ybegp)+\"-\"+str(monbegp).zfill(2)+\"-\"+str(daybegp).zfill(2)\n",
    "dateendp=str(yendp)+\"-\"+str(monendp).zfill(2)+\"-\"+str(dayendp).zfill(2)\n",
    "datebegf=str(ybegf)+\"-\"+str(monbegf).zfill(2)+\"-\"+str(daybegf).zfill(2)\n",
    "dateendf=str(yendf)+\"-\"+str(monendf).zfill(2)+\"-\"+str(dayendf).zfill(2)\n",
    "\n",
    "#set up daterange indexes\n",
    "#daysidp = pd.date_range(datebegp,dateendp,freq='D')\n",
    "#daysidf = pd.date_range(datebegf,dateendf,freq='D')\n",
    "\n",
    "daysidp = xr.cftime_range(datebegp,dateendp,freq='D',calendar='standard')\n",
    "daysidf = xr.cftime_range(datebegf,dateendf,freq='D',calendar='standard')\n",
    "\n",
    "#nb of days\n",
    "ndaysp = len(daysidp)\n",
    "ndaysf = len(daysidf)\n",
    "\n",
    "dayrangep = np.arange(1,ndaysp+1,1)\n",
    "dayrangef = np.arange(1,ndaysf+1,1)\n",
    "\n",
    "latout=np.linspace(-90,90,73)\n",
    "lonout=np.linspace(0,357.5,144)\n",
    "#lonout=np.linspace(0,360,144) # try to remove issues at border\n",
    "\n",
    "# plevuse=[100000,92500,85000,70000,60000,50000,40000,30000,25000,20000,15000,10000,\n",
    "#        7000,5000,3000,2000,1000]\n",
    "# plevuse=[1000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "russian-package",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Members, historical: 40\n",
      "Members, rcp85:  40\n"
     ]
    }
   ],
   "source": [
    "## select models\n",
    "#try with models that have at least 3 members per scenario\n",
    "modlist_3mem = mods_3mem_allscen.index.tolist()\n",
    "modlist_1mem_sel = mods_1mem_hist_ssp585.drop(index=mods_3mem_allscen.index)\n",
    "#modlist_1mem_sel = modlist_1mem_sel.drop(index=['HadGEM3-GC31-MM','HadGEM3-GC31-LL'])\n",
    "model_dl = ['AWI-CM-1-1-MR']\n",
    "modlist = ['ACCESS-ESM1-5']\n",
    "modlist = [model for model in modlist if model not in model_dl]\n",
    "\n",
    "for model in modlist:\n",
    "    print(\"Members, historical: \"+str(nmems_hist[model][0])+\"\\nMembers, rcp85: \",str(dicscen['ssp585'][model][0]))\n",
    "models = pd.Series(modlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b99e717-c623-4cb0-9751-b15da84d1e08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##select scenarios\n",
    "selscen = ['historical','ssp585']\n",
    "var =\"ua\"\n",
    "tres = \"Amon/\"\n",
    "\n",
    "regrid = True\n",
    "plev = [85000]\n",
    "latrg = 2.5\n",
    "lonrg = 2.5\n",
    "#define domain\n",
    "latmin,latmax = 0,90\n",
    "lonmin,lonmax = 0,357.5\n",
    "#nmems_hist = dicscen['historical']\n",
    "#nmems_fut = dicscen['ssp585']\n",
    "#select maximum of members to use \n",
    "nmem_max = 1\n",
    "itercols = [selscen,range(nmem_max)]\n",
    "col_idx= pd.MultiIndex.from_product(itercols,names=[\"scen\",\"imem\"])\n",
    "#get member names\n",
    "memname_df = pd.read_csv('/home/lseverino/MT/metadata/memnames_ssp585_hist_SWM.csv',header=[0,1],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "799baedd-b3b0-424f-a08a-68b8f79b8d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nmem_max = 1\n",
    "rangestr = [str(i) for i in range(nmem_max)]\n",
    "itercols = [selscen,rangestr]\n",
    "col_idx= pd.MultiIndex.from_product(itercols,names=[\"scen\",\"imem\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5914a374-cc29-46ad-a0ba-d21d9b12d6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing historical for ACCESS-ESM1-5 r1i1p1f1...\n",
      "Processing historical for ACCESS-ESM1-5 r3i1p1f1...\n",
      "Processing historical for ACCESS-ESM1-5 r2i1p1f1...\n",
      "interpolating nans...\n",
      "203.69671250879765\n",
      "Processing ssp585 for ACCESS-ESM1-5 r1i1p1f1...\n",
      "Something's wierd about the time axis, decoding manually\n",
      "Look into: /net/atmos/data/cmip6/ssp585/Amon/ua/ACCESS-ESM1-5/r1i1p1f1/gn/ua_Amon_ACCESS-ESM1-5_ssp585_r1i1p1f1_gn_201501-210012.nc\n",
      "Processing ssp585 for ACCESS-ESM1-5 r3i1p1f1...\n",
      "Something's wierd about the time axis, decoding manually\n",
      "Look into: /net/atmos/data/cmip6/ssp585/Amon/ua/ACCESS-ESM1-5/r3i1p1f1/gn/ua_Amon_ACCESS-ESM1-5_ssp585_r3i1p1f1_gn_201501-210012.nc\n",
      "Processing ssp585 for ACCESS-ESM1-5 r2i1p1f1...\n",
      "Something's wierd about the time axis, decoding manually\n",
      "Look into: /net/atmos/data/cmip6/ssp585/Amon/ua/ACCESS-ESM1-5/r2i1p1f1/gn/ua_Amon_ACCESS-ESM1-5_ssp585_r2i1p1f1_gn_201501-210012.nc\n",
      "interpolating nans...\n",
      "507.1749307997525\n"
     ]
    }
   ],
   "source": [
    "##load ua at 850hPa, regrid to 2.5x2.5 \n",
    "\n",
    "nmods = len(models)\n",
    "modout=np.arange(0,nmods)\n",
    "\n",
    "for index, modname in models.iteritems():\n",
    "    start_time = timer()\n",
    "    #nmemsmin = modlist_1mem_sel.loc[modname].min()\n",
    "    #nmems = min((nmemsmin,nmem_max))\n",
    "    #nmems= 1\n",
    "    #memlistp = nmems_hist[modname][1]\n",
    "    #get model resolution\n",
    "    \n",
    "    \n",
    "    for scen in selscen:    \n",
    "           #----sort out the future----\n",
    "            scenpath = pathdic[scen]\n",
    "            memnames_mod = memname_df.loc[modname,scen]\n",
    "            nmems = len(memnames_mod)\n",
    "            memout=np.arange(0,nmems)\n",
    "            for imem in range(nmems):\n",
    "                \n",
    "                #memname = str(memlist[imem])\n",
    "                memname = memname_df.loc[modname,(scen,str(imem))]\n",
    "                print(\"Processing \"+scen+\" for \"+modname+\" \"+memname+\"...\")\n",
    "                \n",
    "                scendir = glob(scenpath+tres+var+\"/\"+modname+\"/\"+memname+\"/*/\")\n",
    "                scendir = scendir[0]\n",
    "                \n",
    "                # read in zonal mean u\n",
    "                if scen == 'historical':\n",
    "                    datebeg = datebegp\n",
    "                    dateend = dateendp\n",
    "                else: \n",
    "                    datebeg = datebegf\n",
    "                    dateend = dateendf\n",
    "                #try:\n",
    "                #    u=read_field(scendir+\"*.nc\", datebeg, dateend,min_lat,max_lat,plev)\n",
    "                #except KeyError:\n",
    "                #    plev = xr.open_mfdataset(scendir+\"*.nc\", coords=\"minimal\", join=\"override\",\n",
    "                #                            decode_times=True, use_cftime=True).plev[2].data.tolist()\n",
    "                #    print(\"Try with new plev: \"+str(plev))\n",
    "                #    u=read_field(scendir+\"*.nc\", datebeg, dateend,min_lat,max_lat,plev)\n",
    "                \n",
    "                try:\n",
    "                    field = read_field(scendir+\"*.nc\", datebeg,dateend,latmin,latmax,None,None,plev)\n",
    "                \n",
    "                except ValueError:\n",
    "                    #assume first file contains what we need\n",
    "                    fpath = glob(scenpath+tres+var+\"/\"+modname+\"/\"+memname+\"/*//*.nc\")[0] \n",
    "                    print(\"Look into: \"+fpath)\n",
    "                    field = read_field(fpath, datebeg,dateend,latmin,latmax,None,None,plev)\n",
    "\n",
    "                utemp = field[var]\n",
    "                \n",
    "                #take mean over pressure\n",
    "                utemp = utemp.mean(dim='plev')\n",
    "                \n",
    "                #initiate array if first member\n",
    "                if imem==0:\n",
    "                    #get lat, lon, latres and lonres\n",
    "                    lat = utemp.lat\n",
    "                    lon = utemp.lon\n",
    "                    min_lat=lat[0].to_numpy()\n",
    "                    max_lat=lat[-1].to_numpy()\n",
    "                    min_lon=lon[0].to_numpy()\n",
    "                    max_lon=lon[-1].to_numpy()\n",
    "                    latres, lonres = get_lat_lon_res(utemp)\n",
    "                    if regrid:\n",
    "                        latres = latrg\n",
    "                        lonres = lonrg\n",
    "                    else:\n",
    "                        latres = latres.round(4)\n",
    "                        lonres = lonres.round(4)\n",
    "                    \n",
    "                    latout = np.arange(min_lat,max_lat,latres)\n",
    "                    lonout = np.arange(min_lon,max_lon,lonres)\n",
    "                    daysid = utemp.time\n",
    "                    ndays = len(daysid)\n",
    "                    uzmem = xr.DataArray(np.zeros([ ndays, latout.size, lonout.size, nmems]), \n",
    "                                          coords=[daysid, latout, lonout, memout],dims=['time','lat','lon','member'], name=scen)\n",
    "                \n",
    "                # check the size\n",
    "                if (utemp.time.size !=  ndays):\n",
    "                    while (u.time.size !=  ndays):\n",
    "                        print(\"something's wrong, ndaysf=\"+str(ndays)+\" but u has size \"+str(u.time.size))\n",
    "                        inc = imem+nmem_max\n",
    "                        memname = memname_df.loc[modname,(scen,str(inc))]#try next member\n",
    "                        print(\"Processing \"+scen+\" for \"+modname+\" \"+memname+\"...\")\n",
    "                \n",
    "                        scendir = glob(scenpath+tres+var+\"/\"+modname+\"/\"+memname+\"/*/\")\n",
    "                        scendir = scendir[0]\n",
    "                        field=read_field(scendir+\"*.nc\", datebeg, dateend,min_lat,max_lat,None,None,plev)\n",
    "                        inc = inc+1\n",
    "    \n",
    "                utemp = field[var]\n",
    "                utemp = utemp.mean(dim='plev')\n",
    "                uinterp = utemp.interp(lat=latout,lon=lonout, method='linear',kwargs={\"fill_value\": None})\n",
    "                uinterp = uinterp.rename({'time': 'time_o'}) #rename to avoid conflicts between indexing and indexed objects\n",
    "        \n",
    "                uzmem.loc[dict(member=imem)]=uinterp\n",
    "        \n",
    "        \n",
    "            # normalize longitude\n",
    "            uzmemn = norm_lon(uzmem)\n",
    "            \n",
    "            \n",
    "            #interpolate nans at 0deg longitude\n",
    "            if np.any(np.isnan(uzmemn.dropna(dim=\"time\",how='all'))):\n",
    "                print('interpolating nans...')\n",
    "                uzmemn = uzmemn.interpolate_na(dim=\"lon\", method=\"linear\")\n",
    "            \n",
    "            #Usfc_EU = def_domain(uzmemn,min_lat,max_lat,min_lon,max_lon)\n",
    "            \n",
    "            #set time indexes\n",
    "            dayrange = np.arange(1,ndays+1,1)\n",
    "            uzmemn = uzmemn.assign_coords({\"day\":(\"time\",dayrange)})\n",
    "            \n",
    "            #select winter months\n",
    "            uzmemn_winE = get_ONDJFM_day(uzmemn,timedim=\"time\")\n",
    "            \n",
    "            #try to remove abonormal values\n",
    "            #Usfc_EU_win = Usfc_EU_win.where(Usfc_EU_win.values >= 0) # values below 0 are discarded\n",
    "            #Usfc_EU_win = Usfc_EU_win.where(Usfc_EU_win.values < 100) # values above 100 are discarded\n",
    "            \n",
    "        \n",
    "            #swap dims to assemble files in the same dataset\n",
    "            \n",
    "            \n",
    "            uzmemn_winE = uzmemn_winE.swap_dims({\"time\":\"day\"})\n",
    "            \n",
    "            #set time index as a data variable\n",
    "            uzmemn_winE = uzmemn_winE.reset_coords()\n",
    "            \n",
    "            if scen == 'historical':\n",
    "                timename = 'timep'\n",
    "            else:\n",
    "                timename = 'timef'\n",
    "            uzmemn_winE = uzmemn_winE.rename(time=timename)\n",
    "            \n",
    "            #save to netcdf\n",
    "            \n",
    "            try:# see if file exist and merge to it\n",
    "                #datain = xr.open_dataset(pathout+modname+'_'+basenamemet+\".nc\")\n",
    "                #merged = xr.merge([datain,Usfc_EU_win])\n",
    "                #merged.to_netcdf(path=pathout+modname+'_'+basenamemet+\".nc\",mode=\"a\",engine=\"scipy\")\n",
    "                uzmemn_winE.to_netcdf(path=pathout+modname+'_'+basenamemet+\".nc\",mode=\"a\")\n",
    "            except: #otherwise directly create the file\n",
    "                #Usfc_EU_win.to_netcdf(path=pathout+modname+'_'+basenamemet+\"_allscens\"+\".nc\",engine=\"scipy\")\n",
    "                uzmemn_winE.to_netcdf(path=pathout+modname+'_'+basenamemet+\".nc\")\n",
    "                          \n",
    "        \n",
    "            time_delta_fut = timer() - start_time\n",
    "            print(time_delta_fut)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2cafdc9-046b-4fd9-891d-0235768502fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get daily sfcWindmax\n",
    "#iterate over scenarios, models, and members\n",
    "#no interpolation to a common grid\n",
    "\n",
    "\n",
    "nmods = len(models)\n",
    "modout=np.arange(0,nmods)\n",
    "\n",
    "for index, modname in models.iteritems():\n",
    "    start_time = timer()\n",
    "    nmemsmin = modlist_1mem_sel.loc[modname].min()\n",
    "    nmems = min((nmemsmin,nmem_max))\n",
    "    memlistp = nmems_hist[modname][1]\n",
    "    #get model resolution\n",
    "\n",
    "    \n",
    "    for scen in selscen:    \n",
    "           #----sort out the future----\n",
    "            nmems_dic = dicscen[scen]\n",
    "            memlist = nmems_dic[modname][1]\n",
    "            scenpath = pathdic[scen]\n",
    "            nmemsf = nmems_dic[modname][0]\n",
    "            memout=np.arange(0,nmems)\n",
    "            for imem in range(nmems):\n",
    "                \n",
    "                memname = str(memlist[imem])\n",
    "                print(\"Processing \"+scen+\" for \"+modname+\" \"+memname+\"...\")\n",
    "                \n",
    "                scendir = glob(scenpath+var+\"/\"+modname+\"/\"+memname+\"/*/\")\n",
    "                scendir = scendir[0]\n",
    "                \n",
    "                # read in zonal mean u\n",
    "                if scen == 'historical':\n",
    "                    datebeg = datebegp\n",
    "                    dateend = dateendp\n",
    "                else: \n",
    "                    datebeg = datebegf\n",
    "                    dateend = dateendf\n",
    "                    \n",
    "                u=read.read_sfc(scendir+\"*.nc\", datebeg,dateend)\n",
    "                utemp = u[var]\n",
    "                \n",
    "                #initiate array if first member\n",
    "                if imem==0:\n",
    "                    #get lat, lon, latres and lonres\n",
    "                    lat = utemp.lat\n",
    "                    lon = utemp.lon\n",
    "                    min_lat=lat[0].to_numpy()\n",
    "                    max_lat=lat[-1].to_numpy()\n",
    "                    min_lon=lon[0].to_numpy()\n",
    "                    max_lon=lon[-1].to_numpy()\n",
    "                    latres, lonres = get_lat_lon_res(utemp)\n",
    "                    if regrid:\n",
    "                        latres = latrg\n",
    "                        lonres = lonrg\n",
    "                    else:\n",
    "                        latres = latres.round(4)\n",
    "                        lonres = lonres.round(4)\n",
    "                    \n",
    "                    latout = np.arange(min_lat,max_lat+latres,latres)\n",
    "                    lonout = np.arange(min_lon,max_lon+lonres,lonres)\n",
    "                    daysid = utemp.time\n",
    "                    ndays = len(daysid)\n",
    "                    \n",
    "                    uzmem = xr.DataArray(np.zeros([ ndays, latout.size, lonout.size, nmems]), \n",
    "                                          coords=[daysid, latout, lonout, memout],dims=['time','lat','lon','member'], name=scen)\n",
    "                \n",
    "                # check the size\n",
    "                if (u.time.size !=  ndays):\n",
    "                    while (u.time.size !=  ndays):\n",
    "                        print(\"something's wrong, ndaysf=\"+str(ndays)+\" but u has size \"+str(u.time.size))\n",
    "                        inc = imem+nmem_max\n",
    "                        memname = str(memlist[inc]) #try next member\n",
    "                        print(\"Processing \"+scen+\" for \"+modname+\" \"+memname+\"...\")\n",
    "                \n",
    "                        scendir = glob(scenpath+tres+var+\"/\"+modname+\"/\"+memname+\"/*/\")\n",
    "                        scendir = scendir[0]\n",
    "                        #u=read.read_sfc(scendir+\"*.nc\", datebeg,dateend)\n",
    "                        inc = inc+1\n",
    "    \n",
    "                memname_df.loc[modname,(scen,imem)] = memname\n",
    "                utemp = u[var]\n",
    "                uinterp = utemp.interp(lat=latout,lon=lonout, method='linear',kwargs={\"fill_value\": None})\n",
    "                uinterp = uinterp.rename({'time': 'time_o'}) #rename to avoid conflicts between indexing and indexed objects\n",
    "        \n",
    "                uzmem.loc[dict(member=imem)]=uinterp\n",
    "        \n",
    "        \n",
    "            # normalize longitude\n",
    "            uzmemn = norm_lon(uzmem)\n",
    "            \n",
    "            \n",
    "            #interpolate nans at 0deg longitude\n",
    "            if np.any(np.isnan(uzmemn.dropna(dim=\"time\",how='all'))):\n",
    "                print('interpolating nans...')\n",
    "                uzmemn = uzmemn.interpolate_na(dim=\"lon\", method=\"linear\")\n",
    "        \n",
    "            \n",
    "            #or\n",
    "            #min_lat,max_lat = 35,73\n",
    "            #min_lon,max_lon = -35,35\n",
    "            \n",
    "            Usfc_EU = def_domain(uzmemn,min_lat,max_lat,min_lon,max_lon)\n",
    "            \n",
    "            #set time indexes\n",
    "            dayrange = np.arange(1,ndays+1,1)\n",
    "            Usfc_EU = Usfc_EU.assign_coords({\"day\":(\"time\",dayrange)})\n",
    "            \n",
    "            #select winter months\n",
    "            Usfc_EU_win = get_ONDJFM_day(Usfc_EU,timedim=\"time\")\n",
    "            \n",
    "            #try to remove abonormal values\n",
    "            Usfc_EU_win = Usfc_EU_win.where(Usfc_EU_win.values >= 0) # values below 0 are discarded\n",
    "            Usfc_EU_win = Usfc_EU_win.where(Usfc_EU_win.values < 100) # values above 100 are discarded\n",
    "            \n",
    "        \n",
    "            #swap dims to assemble files in the same dataset\n",
    "            \n",
    "            \n",
    "            Usfc_EU_win = Usfc_EU_win.swap_dims({\"time\":\"day\"})\n",
    "            \n",
    "            #set time index as a data variable\n",
    "            Usfc_EU_win = Usfc_EU_win.reset_coords()\n",
    "            \n",
    "            if scen == 'historical':\n",
    "                timename = 'timep'\n",
    "            else:\n",
    "                timename = 'timef'\n",
    "            Usfc_EU_win = Usfc_EU_win.rename(time=timename)\n",
    "            \n",
    "            #save to netcdf\n",
    "            \n",
    "            try:# see if file exist and merge to it\n",
    "                #datain = xr.open_dataset(pathout+modname+'_'+basenamemet+\".nc\")\n",
    "                #merged = xr.merge([datain,Usfc_EU_win])\n",
    "                #merged.to_netcdf(path=pathout+modname+'_'+basenamemet+\".nc\",mode=\"a\",engine=\"scipy\")\n",
    "                Usfc_EU_win.to_netcdf(path=pathout+modname+'_'+basenamemet+\".nc\",mode=\"a\")\n",
    "            except: #otherwise directly create the file\n",
    "                #Usfc_EU_win.to_netcdf(path=pathout+modname+'_'+basenamemet+\"_allscens\"+\".nc\",engine=\"scipy\")\n",
    "                Usfc_EU_win.to_netcdf(path=pathout+modname+'_'+basenamemet+\".nc\")\n",
    "                          \n",
    "        \n",
    "            time_delta_fut = timer() - start_time\n",
    "            print(time_delta_fut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e5068-3cc7-4c35-87f9-6ee7847c0f1f",
   "metadata": {},
   "source": [
    "uzmemf_mri = uzmemf\n",
    "utemp_mri = utemp\n",
    "uinterp_mri = uinterp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iacpy3_2021)",
   "language": "python",
   "name": "iacpy3_2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
